"""
‡πÇ‡∏°‡∏î‡∏π‡∏•‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Transformer Module)
========================================

‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ô‡∏µ‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

‡∏ú‡∏π‡πâ‡∏û‡∏±‡∏í‡∏ô‡∏≤: ‡∏ó‡∏µ‡∏°‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: ‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô 2568
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Any, Optional, Union, Callable
from datetime import datetime, timedelta
import re


class DataTransformer:
    """
    ‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    
    ‡∏Ñ‡∏•‡∏≤‡∏™‡∏ô‡∏µ‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:
    - ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà
    - ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
    - ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏´‡∏±‡∏™‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤
    - ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    - ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå (Feature Engineering)
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™ DataTransformer
        
        Args:
            config (Dict): ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        """
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        self.transformation_log = []  # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á
        self.value_mappings = {}  # ‡πÄ‡∏Å‡πá‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏õ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ
        
    def transform_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å
        
        Args:
            data (pd.DataFrame): ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß
            
        Returns:
            pd.DataFrame: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏•‡πâ‡∏ß
        """
        self.logger.info("üîÑ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        
        transformed_data = data.copy()
        
        # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        transformation_steps = [
            ("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà", self._create_new_features),
            ("‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏´‡∏±‡∏™‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤", self._map_values),
            ("‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå", self._merge_split_columns),
            ("‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢", self._final_type_conversion),
            ("‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô", self._normalize_standardize)
        ]
        
        for step_name, step_function in transformation_steps:
            self.logger.info(f"üîß {step_name}...")
            try:
                transformed_data = step_function(transformed_data)
                self.transformation_log.append(f"‚úÖ {step_name} - ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
            except Exception as e:
                error_msg = f"‚ùå {step_name} - ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"
                self.logger.error(error_msg)
                self.transformation_log.append(error_msg)
                
        self._log_transformation_summary(data, transformed_data)
        self.logger.info("‚úÖ ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        
        return transformed_data
    
    def _create_new_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà"""
        self.logger.info("üèóÔ∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        date_columns = data.select_dtypes(include=['datetime64[ns]']).columns
        for column in date_columns:
            self._create_date_features(data, column)
            
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        text_columns = data.select_dtypes(include=['object']).columns
        for column in text_columns:
            self._create_text_features(data, column)
            
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
        numeric_columns = data.select_dtypes(include=[np.number]).columns
        if len(numeric_columns) >= 2:
            self._create_numeric_features(data, numeric_columns)
            
        return data
    
    def _create_date_features(self, data: pd.DataFrame, column: str):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà"""
        base_name = column.replace('_date', '').replace('_time', '')
        
        # ‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        data[f'{base_name}_year'] = data[column].dt.year
        data[f'{base_name}_month'] = data[column].dt.month
        data[f'{base_name}_day'] = data[column].dt.day
        data[f'{base_name}_weekday'] = data[column].dt.weekday
        data[f'{base_name}_quarter'] = data[column].dt.quarter
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
        data[f'{base_name}_is_weekend'] = data[column].dt.weekday >= 5
        data[f'{base_name}_days_from_today'] = (datetime.now() - data[column]).dt.days
        
        self.logger.info(f"üìÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{column}'")
    
    def _create_text_features(self, data: pd.DataFrame, column: str):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        data[f'{column}_length'] = data[column].astype(str).str.len()
        
        # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥
        data[f'{column}_word_count'] = data[column].astype(str).str.split().str.len()
        
        # ‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        data[f'{column}_has_numbers'] = data[column].astype(str).str.contains(r'\d', regex=True)
        
        # ‡∏°‡∏µ‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        data[f'{column}_has_special'] = data[column].astype(str).str.contains(r'[^a-zA-Z0-9\s]', regex=True)
        
        # ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        data[f'{column}_is_upper'] = data[column].astype(str).str.isupper()
        
        self.logger.info(f"üìù ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{column}'")
    
    def _create_numeric_features(self, data: pd.DataFrame, numeric_columns: pd.Index):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç"""
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏° (Aggregation Features)
        if len(numeric_columns) >= 2:
            # ‡∏ú‡∏•‡∏£‡∏ß‡∏°
            data['total_sum'] = data[numeric_columns].sum(axis=1)
            
            # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
            data['average'] = data[numeric_columns].mean(axis=1)
            
            # ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î
            data['max_value'] = data[numeric_columns].max(axis=1)
            data['min_value'] = data[numeric_columns].min(axis=1)
            
            # ‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏≤ (Range)
            data['value_range'] = data['max_value'] - data['min_value']
            
            self.logger.info("üî¢ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç")
    
    def _map_values(self, data: pd.DataFrame) -> pd.DataFrame:
        """‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏´‡∏±‡∏™‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
        self.logger.info("üó∫Ô∏è ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏´‡∏±‡∏™‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤")
        
        # ‡πÅ‡∏°‡∏õ‡∏Ñ‡πà‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
        common_mappings = {
            # ‡πÅ‡∏°‡∏õ‡∏Ñ‡πà‡∏≤‡∏ö‡∏π‡∏•‡∏µ‡∏ô
            'boolean_mappings': {
                'yes': True, 'no': False, 'y': True, 'n': False,
                'true': True, 'false': False, '1': True, '0': False,
                '‡πÉ‡∏ä‡πà': True, '‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà': False, '‡πÉ‡∏ä‡πâ': True, '‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ': False
            },
            
            # ‡πÅ‡∏°‡∏õ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤
            'education_mappings': {
                '‡∏õ‡∏£‡∏∞‡∏ñ‡∏°': 1, '‡∏°‡∏±‡∏ò‡∏¢‡∏°': 2, '‡∏õ‡∏ß‡∏ä': 3, '‡∏õ‡∏ß‡∏™': 4,
                '‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ': 5, '‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡πÇ‡∏ó': 6, '‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡πÄ‡∏≠‡∏Å': 7,
                'primary': 1, 'secondary': 2, 'bachelor': 5, 'master': 6, 'phd': 7
            },
            
            # ‡πÅ‡∏°‡∏õ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à
            'size_mappings': {
                '‡πÄ‡∏•‡πá‡∏Å': 1, '‡∏Å‡∏•‡∏≤‡∏á': 2, '‡πÉ‡∏´‡∏ç‡πà': 3,
                'small': 1, 'medium': 2, 'large': 3,
                's': 1, 'm': 2, 'l': 3, 'xl': 4
            }
        }
        
        # ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏õ‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
        for column in data.columns:
            if data[column].dtype == 'object':
                column_lower = column.lower()
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
                if any(keyword in column_lower for keyword in ['bool', 'flag', 'is_', 'has_']):
                    data[column] = self._apply_mapping(data[column], common_mappings['boolean_mappings'])
                    self.logger.info(f"‚úÖ ‡πÅ‡∏°‡∏õ‡∏Ñ‡πà‡∏≤‡∏ö‡∏π‡∏•‡∏µ‡∏ô‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{column}'")
                    
                elif any(keyword in column_lower for keyword in ['education', 'degree', '‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤']):
                    data[column] = self._apply_mapping(data[column], common_mappings['education_mappings'])
                    self.logger.info(f"üìö ‡πÅ‡∏°‡∏õ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{column}'")
                    
                elif any(keyword in column_lower for keyword in ['size', '‡∏Ç‡∏ô‡∏≤‡∏î']):
                    data[column] = self._apply_mapping(data[column], common_mappings['size_mappings'])
                    self.logger.info(f"üìè ‡πÅ‡∏°‡∏õ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{column}'")
        
        return data
    
    def _apply_mapping(self, series: pd.Series, mapping: Dict) -> pd.Series:
        """‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏õ‡∏Å‡∏±‡∏ö Series"""
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
        series_mapped = series.astype(str).str.lower().map(mapping)
        
        # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏õ
        return series_mapped.fillna(series)
    
    def _merge_split_columns(self, data: pd.DataFrame) -> pd.DataFrame:
        """‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå"""
        self.logger.info("üîó ‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå")
        
        # ‡∏£‡∏ß‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡∏∑‡πà‡∏≠ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        name_columns = [col for col in data.columns if any(keyword in col.lower() 
                       for keyword in ['first_name', 'last_name', '‡∏ä‡∏∑‡πà‡∏≠', '‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•'])]
        
        if len(name_columns) >= 2:
            data['full_name'] = data[name_columns].apply(
                lambda row: ' '.join(row.dropna().astype(str)), axis=1
            )
            self.logger.info(f"üë§ ‡∏£‡∏ß‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡∏∑‡πà‡∏≠: {name_columns}")
        
        # ‡∏£‡∏ß‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        address_columns = [col for col in data.columns if any(keyword in col.lower() 
                          for keyword in ['address', 'street', 'city', 'province', '‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà', '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î'])]
        
        if len(address_columns) >= 2:
            data['full_address'] = data[address_columns].apply(
                lambda row: ', '.join(row.dropna().astype(str)), axis=1
            )
            self.logger.info(f"üè† ‡∏£‡∏ß‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà: {address_columns}")
        
        # ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏≠‡∏µ‡πÄ‡∏°‡∏• (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ domain)
        email_columns = [col for col in data.columns if 'email' in col.lower() or '‡∏≠‡∏µ‡πÄ‡∏°‡∏•' in col.lower()]
        for column in email_columns:
            if column in data.columns:
                data[f'{column}_domain'] = data[column].astype(str).str.extract(r'@([^.]+)')
                self.logger.info(f"üìß ‡πÅ‡∏¢‡∏Å domain ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{column}'")
        
        return data
    
    def _final_type_conversion(self, data: pd.DataFrame) -> pd.DataFrame:
        """‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢"""
        self.logger.info("üéØ ‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢")
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÅ‡∏ï‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô object
        for column in data.columns:
            if data[column].dtype == 'object':
                # ‡∏•‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
                try:
                    numeric_data = pd.to_numeric(data[column], errors='coerce')
                    if numeric_data.notna().sum() / len(data) > 0.8:  # ‡∏ñ‡πâ‡∏≤ 80% ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏î‡πâ
                        data[column] = numeric_data
                        self.logger.info(f"üî¢ ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{column}' ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç")
                except:
                    pass
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ö‡∏π‡∏•‡∏µ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
        for column in data.columns:
            if data[column].dtype in ['int64', 'float64']:
                unique_values = data[column].dropna().unique()
                if len(unique_values) == 2 and set(unique_values).issubset({0, 1, True, False}):
                    data[column] = data[column].astype(bool)
                    self.logger.info(f"‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{column}' ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏π‡∏•‡∏µ‡∏ô")
        
        return data
    
    def _normalize_standardize(self, data: pd.DataFrame) -> pd.DataFrame:
        """‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        self.logger.info("üìê ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        
        numeric_columns = data.select_dtypes(include=[np.number]).columns
        
        # Standardization (Z-score normalization) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏õ‡∏Å‡∏ï‡∏¥
        for column in numeric_columns:
            if column.endswith(('_id', '_code', '_count', '_length')):
                continue  # ‡∏Ç‡πâ‡∏≤‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£ normalize
                
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            if data[column].std() > 0:  # ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢
                data[f'{column}_normalized'] = (data[column] - data[column].mean()) / data[column].std()
                self.logger.info(f"üìä ‡∏õ‡∏£‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô Z-score ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{column}'")
        
        return data
    
    def create_custom_feature(self, data: pd.DataFrame, feature_name: str, 
                            feature_function: Callable, *args, **kwargs) -> pd.DataFrame:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÅ‡∏ö‡∏ö‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á
        
        Args:
            data: DataFrame ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            feature_name: ‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà
            feature_function: ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå
            *args, **kwargs: ‡∏≠‡∏≤‡∏£‡πå‡∏Å‡∏¥‡∏ß‡πÄ‡∏°‡∏ô‡∏ï‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
            
        Returns:
            DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà
        """
        try:
            data[feature_name] = feature_function(data, *args, **kwargs)
            self.logger.info(f"üé® ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á: {feature_name}")
            self.transformation_log.append(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå '{feature_name}' - ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        except Exception as e:
            error_msg = f"‚ùå ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå '{feature_name}' - ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"
            self.logger.error(error_msg)
            self.transformation_log.append(error_msg)
            
        return data
    
    def apply_custom_mapping(self, data: pd.DataFrame, column: str, 
                           mapping: Dict[str, Any]) -> pd.DataFrame:
        """
        ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á
        
        Args:
            data: DataFrame ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            column: ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏õ
            mapping: Dictionary ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏õ
            
        Returns:
            DataFrame ‡∏ó‡∏µ‡πà‡πÅ‡∏°‡∏õ‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡πâ‡∏ß
        """
        if column in data.columns:
            data[column] = self._apply_mapping(data[column], mapping)
            self.value_mappings[column] = mapping
            self.logger.info(f"üó∫Ô∏è ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏õ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{column}'")
            self.transformation_log.append(f"‚úÖ ‡πÅ‡∏°‡∏õ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{column}' - ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        else:
            self.logger.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{column}'")
            
        return data
    
    def _log_transformation_summary(self, original_data: pd.DataFrame, 
                                  transformed_data: pd.DataFrame):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        original_columns = len(original_data.columns)
        transformed_columns = len(transformed_data.columns)
        new_columns = transformed_columns - original_columns
        
        self.logger.info("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:")
        self.logger.info(f"   - ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏î‡∏¥‡∏°: {original_columns}")
        self.logger.info(f"   - ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà: {transformed_columns}")
        self.logger.info(f"   - ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°: {new_columns}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô
        if new_columns > 0:
            original_cols = set(original_data.columns)
            new_cols = [col for col in transformed_data.columns if col not in original_cols]
            self.logger.info(f"   - ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà: {new_cols[:10]}")  # ‡πÅ‡∏™‡∏î‡∏á 10 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏£‡∏Å
    
    def get_transformation_summary(self) -> List[str]:
        """‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        return self.transformation_log.copy()
    
    def get_value_mappings(self) -> Dict[str, Dict]:
        """‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏õ‡∏Ñ‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        return self.value_mappings.copy()
    
    def reset_log(self):
        """‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á"""
        self.transformation_log = []
        self.value_mappings = {}
