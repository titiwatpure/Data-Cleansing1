"""
‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Validator Module)
=========================================

‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ô‡∏µ‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö

‡∏ú‡∏π‡πâ‡∏û‡∏±‡∏í‡∏ô‡∏≤: ‡∏ó‡∏µ‡∏°‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: ‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô 2568
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import re


class DataValidator:
    """
    ‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    
    ‡∏Ñ‡∏•‡∏≤‡∏™‡∏ô‡∏µ‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:
    - ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
    - ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
    - ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á
    - ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥
    - ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™ DataValidator
        
        Args:
            config (Dict): ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
        """
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        self.validation_results = {}
        self.quality_metrics = {}
        
    def validate_data(self, original_data: pd.DataFrame, 
                     cleaned_data: pd.DataFrame) -> Dict[str, Any]:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
        
        Args:
            original_data (pd.DataFrame): ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            cleaned_data (pd.DataFrame): ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß
            
        Returns:
            Dict: ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
        """
        self.logger.info("üîç ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß
        original_quality = self._assess_data_quality(original_data, "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö")
        cleaned_quality = self._assess_data_quality(cleaned_data, "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß")
        
        # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
        comparison = self._compare_datasets(original_data, cleaned_data)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞
        specific_validations = self._perform_specific_validations(cleaned_data)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ
        validation_summary = self._create_validation_summary(
            original_quality, cleaned_quality, comparison, specific_validations
        )
        
        self.validation_results = {
            'original_quality': original_quality,
            'cleaned_quality': cleaned_quality,
            'comparison': comparison,
            'specific_validations': specific_validations,
            'summary': validation_summary
        }
        
        self.logger.info("‚úÖ ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        return self.validation_results
    
    def _assess_data_quality(self, data: pd.DataFrame, dataset_name: str) -> Dict[str, Any]:
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        self.logger.info(f"üìä ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û: {dataset_name}")
        
        total_cells = data.shape[0] * data.shape[1]
        missing_cells = data.isnull().sum().sum()
        
        quality_assessment = {
            'dataset_name': dataset_name,
            'basic_info': {
                'rows': data.shape[0],
                'columns': data.shape[1],
                'total_cells': total_cells,
                'memory_usage_mb': data.memory_usage(deep=True).sum() / 1024 / 1024
            },
            'completeness': {
                'missing_cells': missing_cells,
                'missing_percentage': (missing_cells / total_cells) * 100 if total_cells > 0 else 0,
                'complete_rows': data.dropna().shape[0],
                'complete_rows_percentage': (data.dropna().shape[0] / data.shape[0]) * 100 if data.shape[0] > 0 else 0
            },
            'uniqueness': self._assess_uniqueness(data),
            'consistency': self._assess_consistency(data),
            'accuracy': self._assess_accuracy(data),
            'validity': self._assess_validity(data)
        }
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°
        quality_assessment['overall_score'] = self._calculate_quality_score(quality_assessment)
        
        return quality_assessment
    
    def _assess_uniqueness(self, data: pd.DataFrame) -> Dict[str, Any]:
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        duplicate_rows = data.duplicated().sum()
        
        uniqueness = {
            'duplicate_rows': duplicate_rows,
            'duplicate_percentage': (duplicate_rows / len(data)) * 100 if len(data) > 0 else 0,
            'unique_rows': len(data) - duplicate_rows,
            'uniqueness_score': ((len(data) - duplicate_rows) / len(data)) * 100 if len(data) > 0 else 100
        }
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡πâ‡∏≥‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
        column_uniqueness = {}
        for column in data.columns:
            unique_values = data[column].nunique()
            total_values = data[column].count()
            column_uniqueness[column] = {
                'unique_values': unique_values,
                'total_values': total_values,
                'uniqueness_ratio': unique_values / total_values if total_values > 0 else 0
            }
        
        uniqueness['column_uniqueness'] = column_uniqueness
        return uniqueness
    
    def _assess_consistency(self, data: pd.DataFrame) -> Dict[str, Any]:
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        consistency_issues = []
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        for column in data.columns:
            if data[column].dtype == 'object':
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
                pattern_consistency = self._check_pattern_consistency(data[column], column)
                if pattern_consistency['issues']:
                    consistency_issues.extend(pattern_consistency['issues'])
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•
        for column in data.select_dtypes(include=[np.number]).columns:
            range_check = self._check_reasonable_ranges(data[column], column)
            if range_check['issues']:
                consistency_issues.extend(range_check['issues'])
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        for column in data.select_dtypes(include=['datetime64[ns]']).columns:
            date_check = self._check_date_consistency(data[column], column)
            if date_check['issues']:
                consistency_issues.extend(date_check['issues'])
        
        consistency_score = max(0, 100 - len(consistency_issues) * 10)  # ‡∏•‡∏î‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô 10% ‡∏ï‡πà‡∏≠‡∏õ‡∏±‡∏ç‡∏´‡∏≤
        
        return {
            'issues': consistency_issues,
            'issue_count': len(consistency_issues),
            'consistency_score': consistency_score
        }
    
    def _assess_accuracy(self, data: pd.DataFrame) -> Dict[str, Any]:
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        accuracy_issues = []
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏≠‡∏µ‡πÄ‡∏°‡∏•
        email_columns = [col for col in data.columns if 'email' in col.lower() or '‡∏≠‡∏µ‡πÄ‡∏°‡∏•' in col.lower()]
        for column in email_columns:
            if column in data.columns:
                email_check = self._validate_email_format(data[column], column)
                if email_check['invalid_count'] > 0:
                    accuracy_issues.append(email_check)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå
        phone_columns = [col for col in data.columns if any(keyword in col.lower() 
                        for keyword in ['phone', 'tel', 'mobile', '‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå', '‡πÄ‡∏ö‡∏≠‡∏£‡πå'])]
        for column in phone_columns:
            if column in data.columns:
                phone_check = self._validate_phone_format(data[column], column)
                if phone_check['invalid_count'] > 0:
                    accuracy_issues.append(phone_check)
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
        accuracy_score = max(0, 100 - len(accuracy_issues) * 15)  # ‡∏•‡∏î‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô 15% ‡∏ï‡πà‡∏≠‡∏õ‡∏±‡∏ç‡∏´‡∏≤
        
        return {
            'issues': accuracy_issues,
            'issue_count': len(accuracy_issues),
            'accuracy_score': accuracy_score
        }
    
    def _assess_validity(self, data: pd.DataFrame) -> Dict[str, Any]:
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏Å‡∏é‡πÄ‡∏Å‡∏ì‡∏ë‡πå"""
        validity_issues = []
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏≠‡∏Å‡∏ô‡∏≠‡∏Å‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï
        for column in data.select_dtypes(include=[np.number]).columns:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏•‡∏ö‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏ö
            if any(keyword in column.lower() for keyword in ['age', 'price', 'amount', 'count', 'quantity']):
                negative_count = (data[column] < 0).sum()
                if negative_count > 0:
                    validity_issues.append({
                        'column': column,
                        'issue': f'‡∏û‡∏ö‡∏Ñ‡πà‡∏≤‡∏•‡∏ö {negative_count} ‡∏à‡∏∏‡∏î ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏ö',
                        'severity': '‡∏™‡∏π‡∏á'
                    })
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ (outliers)
            if len(data[column].dropna()) > 0:
                Q1 = data[column].quantile(0.25)
                Q3 = data[column].quantile(0.75)
                IQR = Q3 - Q1
                outlier_count = len(data[(data[column] < Q1 - 3 * IQR) | (data[column] > Q3 + 3 * IQR)])
                
                if outlier_count > len(data) * 0.05:  # ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 5%
                    validity_issues.append({
                        'column': column,
                        'issue': f'‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏°‡∏≤‡∏Å {outlier_count} ‡∏à‡∏∏‡∏î ({outlier_count/len(data)*100:.1f}%)',
                        'severity': '‡∏Å‡∏•‡∏≤‡∏á'
                    })
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏Å‡∏é
        validity_score = max(0, 100 - len(validity_issues) * 12)  # ‡∏•‡∏î‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô 12% ‡∏ï‡πà‡∏≠‡∏õ‡∏±‡∏ç‡∏´‡∏≤
        
        return {
            'issues': validity_issues,
            'issue_count': len(validity_issues),
            'validity_score': validity_score
        }
    
    def _check_pattern_consistency(self, series: pd.Series, column_name: str) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö"""
        issues = []
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå
        if series.dtype == 'object':
            mixed_case_count = sum(1 for x in series.dropna() if isinstance(x, str) and 
                                 x != x.upper() and x != x.lower() and any(c.isalpha() for c in x))
            
            if mixed_case_count > len(series) * 0.1:  # ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 10%
                issues.append({
                    'column': column_name,
                    'issue': f'‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÑ‡∏°‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á {mixed_case_count} ‡∏à‡∏∏‡∏î',
                    'severity': '‡∏ï‡πà‡∏≥'
                })
        
        return {'issues': issues}
    
    def _check_reasonable_ranges(self, series: pd.Series, column_name: str) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•"""
        issues = []
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏≠‡∏≤‡∏¢‡∏∏
        if 'age' in column_name.lower() or '‡∏≠‡∏≤‡∏¢‡∏∏' in column_name.lower():
            unreasonable_age = ((series < 0) | (series > 150)).sum()
            if unreasonable_age > 0:
                issues.append({
                    'column': column_name,
                    'issue': f'‡∏≠‡∏≤‡∏¢‡∏∏‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏• {unreasonable_age} ‡∏à‡∏∏‡∏î',
                    'severity': '‡∏™‡∏π‡∏á'
                })
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå
        if 'percent' in column_name.lower() or '‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå' in column_name.lower():
            invalid_percent = ((series < 0) | (series > 100)).sum()
            if invalid_percent > 0:
                issues.append({
                    'column': column_name,
                    'issue': f'‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á {invalid_percent} ‡∏à‡∏∏‡∏î',
                    'severity': '‡∏™‡∏π‡∏á'
                })
        
        return {'issues': issues}
    
    def _check_date_consistency(self, series: pd.Series, column_name: str) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà"""
        issues = []
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï
        future_dates = (series > datetime.now()).sum()
        if future_dates > 0:
            issues.append({
                'column': column_name,
                'issue': f'‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï {future_dates} ‡∏à‡∏∏‡∏î',
                'severity': '‡∏Å‡∏•‡∏≤‡∏á'
            })
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
        very_old_dates = (series < datetime(1900, 1, 1)).sum()
        if very_old_dates > 0:
            issues.append({
                'column': column_name,
                'issue': f'‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ {very_old_dates} ‡∏à‡∏∏‡∏î',
                'severity': '‡∏Å‡∏•‡∏≤‡∏á'
            })
        
        return {'issues': issues}
    
    def _validate_email_format(self, series: pd.Series, column_name: str) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏≠‡∏µ‡πÄ‡∏°‡∏•"""
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        
        valid_emails = series.astype(str).str.match(email_pattern).sum()
        total_emails = series.count()
        invalid_count = total_emails - valid_emails
        
        return {
            'column': column_name,
            'issue': f'‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á {invalid_count} ‡∏à‡∏∏‡∏î ‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {total_emails} ‡∏à‡∏∏‡∏î',
            'invalid_count': invalid_count,
            'validity_percentage': (valid_emails / total_emails * 100) if total_emails > 0 else 0,
            'severity': '‡∏Å‡∏•‡∏≤‡∏á' if invalid_count > total_emails * 0.1 else '‡∏ï‡πà‡∏≥'
        }
    
    def _validate_phone_format(self, series: pd.Series, column_name: str) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå"""
        phone_patterns = [
            r'^\d{3}-\d{3}-\d{4}$',      # 123-456-7890
            r'^\(\d{3}\)\s\d{3}-\d{4}$', # (123) 456-7890
            r'^\d{10}$',                 # 1234567890
            r'^0\d{8,9}$',               # 0812345678 (‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ó‡∏¢)
        ]
        
        valid_phones = 0
        for phone in series.dropna():
            phone_str = str(phone).strip()
            if any(re.match(pattern, phone_str) for pattern in phone_patterns):
                valid_phones += 1
        
        total_phones = series.count()
        invalid_count = total_phones - valid_phones
        
        return {
            'column': column_name,
            'issue': f'‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á {invalid_count} ‡∏à‡∏∏‡∏î ‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {total_phones} ‡∏à‡∏∏‡∏î',
            'invalid_count': invalid_count,
            'validity_percentage': (valid_phones / total_phones * 100) if total_phones > 0 else 0,
            'severity': '‡∏Å‡∏•‡∏≤‡∏á' if invalid_count > total_phones * 0.1 else '‡∏ï‡πà‡∏≥'
        }
    
    def _compare_datasets(self, original: pd.DataFrame, cleaned: pd.DataFrame) -> Dict[str, Any]:
        """‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î"""
        comparison = {
            'rows_changed': {
                'original': len(original),
                'cleaned': len(cleaned),
                'difference': len(cleaned) - len(original),
                'percentage_change': ((len(cleaned) - len(original)) / len(original) * 100) if len(original) > 0 else 0
            },
            'columns_changed': {
                'original': len(original.columns),
                'cleaned': len(cleaned.columns),
                'difference': len(cleaned.columns) - len(original.columns),
                'new_columns': list(set(cleaned.columns) - set(original.columns)),
                'removed_columns': list(set(original.columns) - set(cleaned.columns))
            },
            'missing_data_improvement': {
                'original_missing': original.isnull().sum().sum(),
                'cleaned_missing': cleaned.isnull().sum().sum(),
                'improvement': original.isnull().sum().sum() - cleaned.isnull().sum().sum()
            }
        }
        
        return comparison
    
    def _perform_specific_validations(self, data: pd.DataFrame) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á"""
        validations = {}
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        validations['data_distribution'] = self._check_data_distribution(data)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
        validations['column_relationships'] = self._check_column_relationships(data)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢
        validations['business_rules'] = self._check_business_rules(data)
        
        return validations
    
    def _check_data_distribution(self, data: pd.DataFrame) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        distribution_info = {}
        
        for column in data.select_dtypes(include=[np.number]).columns:
            series = data[column].dropna()
            if len(series) > 0:
                distribution_info[column] = {
                    'mean': float(series.mean()),
                    'median': float(series.median()),
                    'std': float(series.std()),
                    'skewness': float(series.skew()),
                    'kurtosis': float(series.kurtosis())
                }
        
        return distribution_info
    
    def _check_column_relationships(self, data: pd.DataFrame) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå"""
        relationships = {}
        
        numeric_columns = data.select_dtypes(include=[np.number]).columns
        if len(numeric_columns) >= 2:
            correlation_matrix = data[numeric_columns].corr()
            
            # ‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏£‡∏á (> 0.8 ‡∏´‡∏£‡∏∑‡∏≠ < -0.8)
            strong_correlations = []
            for i, col1 in enumerate(correlation_matrix.columns):
                for j, col2 in enumerate(correlation_matrix.columns):
                    if i < j:  # ‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏ã‡πâ‡∏≥
                        corr_value = correlation_matrix.loc[col1, col2]
                        if abs(corr_value) > 0.8:
                            strong_correlations.append({
                                'column1': col1,
                                'column2': col2,
                                'correlation': float(corr_value)
                            })
            
            relationships['strong_correlations'] = strong_correlations
        
        return relationships
    
    def _check_business_rules(self, data: pd.DataFrame) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏é‡∏ó‡∏≤‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à"""
        violations = []
        
        # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏é‡∏ó‡∏≤‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à
        # ‡∏Å‡∏é 1: ‡∏≠‡∏≤‡∏¢‡∏∏‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏ß‡∏±‡∏ô‡πÄ‡∏Å‡∏¥‡∏î
        age_columns = [col for col in data.columns if 'age' in col.lower() or '‡∏≠‡∏≤‡∏¢‡∏∏' in col.lower()]
        birth_columns = [col for col in data.columns if any(keyword in col.lower() 
                        for keyword in ['birth', 'born', '‡πÄ‡∏Å‡∏¥‡∏î'])]
        
        if age_columns and birth_columns:
            for age_col in age_columns:
                for birth_col in birth_columns:
                    if age_col in data.columns and birth_col in data.columns:
                        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏≠‡∏≤‡∏¢‡∏∏‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏ô‡πÄ‡∏Å‡∏¥‡∏î
                        # (‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏∞‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ)
                        violations.append({
                            'rule': f'‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á {age_col} ‡πÅ‡∏•‡∏∞ {birth_col}',
                            'status': '‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°'
                        })
        
        return {'violations': violations}
    
    def _calculate_quality_score(self, quality_assessment: Dict[str, Any]) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°"""
        # ‡∏ô‡πâ‡∏≥‡∏´‡∏±‡∏Å: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå 30%, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥ 25%, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á 25%, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á 20%
        completeness_score = 100 - quality_assessment['completeness']['missing_percentage']
        uniqueness_score = quality_assessment['uniqueness']['uniqueness_score']
        consistency_score = quality_assessment['consistency']['consistency_score']
        accuracy_score = quality_assessment['accuracy']['accuracy_score']
        
        overall_score = (
            completeness_score * 0.30 +
            uniqueness_score * 0.25 +
            consistency_score * 0.25 +
            accuracy_score * 0.20
        )
        
        return round(overall_score, 1)
    
    def _create_validation_summary(self, original_quality: Dict, cleaned_quality: Dict,
                                 comparison: Dict, specific_validations: Dict) -> Dict[str, Any]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö"""
        return {
            'quality_improvement': {
                'original_score': original_quality['overall_score'],
                'cleaned_score': cleaned_quality['overall_score'],
                'improvement': cleaned_quality['overall_score'] - original_quality['overall_score']
            },
            'data_changes': {
                'rows_removed': max(0, -comparison['rows_changed']['difference']),
                'rows_added': max(0, comparison['rows_changed']['difference']),
                'columns_added': len(comparison['columns_changed']['new_columns']),
                'missing_data_reduced': comparison['missing_data_improvement']['improvement']
            },
            'recommendations': self._generate_recommendations(cleaned_quality, specific_validations),
            'validation_timestamp': datetime.now().isoformat()
        }
    
    def _generate_recommendations(self, quality_assessment: Dict, 
                                specific_validations: Dict) -> List[str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        recommendations = []
        
        # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
        if quality_assessment['overall_score'] < 80:
            recommendations.append("‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏±‡∏á‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ 80% ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
        
        # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
        if quality_assessment['completeness']['missing_percentage'] > 10:
            recommendations.append("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 10% ‡∏Ñ‡∏ß‡∏£‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
        
        # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡πâ‡∏≥
        if quality_assessment['uniqueness']['duplicate_percentage'] > 5:
            recommendations.append("‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 5% ‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥")
        
        # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á
        if quality_assessment['consistency']['issue_count'] > 0:
            recommendations.append(f"‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á {quality_assessment['consistency']['issue_count']} ‡∏à‡∏∏‡∏î ‡∏Ñ‡∏ß‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç")
        
        # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
        if quality_assessment['accuracy']['issue_count'] > 0:
            recommendations.append(f"‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á {quality_assessment['accuracy']['issue_count']} ‡∏à‡∏∏‡∏î ‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö")
        
        return recommendations
    
    def get_validation_results(self) -> Dict[str, Any]:
        """‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö"""
        return self.validation_results
    
    def export_validation_report(self, file_path: str, format: str = 'json'):
        """‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö"""
        if format.lower() == 'json':
            import json
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(self.validation_results, f, ensure_ascii=False, indent=2, default=str)
        
        self.logger.info(f"‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á: {file_path}")
